{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ30jJqgXylE",
        "outputId": "bbe6bbc5-5a86-42e1-a4d4-b80c34793314"
      },
      "source": [
        "!pip install git+https://github.com/catalyst-team/catalyst.git\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from catalyst.utils import set_global_seed\n",
        "from catalyst.dl import SupervisedRunner, Runner\n",
        "from catalyst.utils import metrics\n",
        "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback, F1ScoreCallback, EarlyStoppingCallback, CriterionCallback\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset as BaseDataset\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "\n",
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "pd.options.display.width = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/catalyst-team/catalyst.git\n",
            "  Cloning https://github.com/catalyst-team/catalyst.git to /tmp/pip-req-build-mxt6rnq_\n",
            "  Running command git clone -q https://github.com/catalyst-team/catalyst.git /tmp/pip-req-build-mxt6rnq_\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied (use --upgrade to upgrade): catalyst==20.10.1 from git+https://github.com/catalyst-team/catalyst.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (1.7.0+cu101)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (2.1)\n",
            "Requirement already satisfied: pandas>=0.22 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (1.1.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (5.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (1.18.5)\n",
            "Requirement already satisfied: tensorboard>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (2.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (3.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (20.4)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (2.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (0.22.2.post1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (4.4.1)\n",
            "Requirement already satisfied: GitPython>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (3.1.11)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from catalyst==20.10.1) (4.41.1)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst==20.10.1) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst==20.10.1) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->catalyst==20.10.1) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->catalyst==20.10.1) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->catalyst==20.10.1) (3.12.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst==20.10.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22->catalyst==20.10.1) (2.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.10.1) (50.3.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.10.1) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.10.1) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.10.1) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.10.1) (4.3.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.10.1) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.10.1) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->catalyst==20.10.1) (1.0.18)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (1.7.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (1.33.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (0.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (1.17.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (0.35.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14.0->catalyst==20.10.1) (0.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.10.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.10.1) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catalyst==20.10.1) (2.4.7)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst==20.10.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->catalyst==20.10.1) (0.17.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->catalyst==20.10.1) (1.3.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=3.1.1->catalyst==20.10.1) (4.0.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->catalyst==20.10.1) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst==20.10.1) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->catalyst==20.10.1) (0.2.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.10.1) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.10.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.10.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst==20.10.1) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.10.1) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.10.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.10.1) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst==20.10.1) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst==20.10.1) (1.3.0)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.1->catalyst==20.10.1) (3.0.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst==20.10.1) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst==20.10.1) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst==20.10.1) (3.1.0)\n",
            "Building wheels for collected packages: catalyst\n",
            "  Building wheel for catalyst (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for catalyst: filename=catalyst-20.10.1-cp36-none-any.whl size=522813 sha256=7fa4e5db8cecc967f38c7586be80396c2fa23ce99264ca3c3a6ef0bd859ee649\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ayy9g3c/wheels/c0/f3/9d/bf3eeb5c08ad8c5dea0e8e4090885a71495eb4c8bea1f87516\n",
            "Successfully built catalyst\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv8TX_p9HgP8"
      },
      "source": [
        "# reproduce\n",
        "SEED = 15\n",
        "set_global_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# determine the supported device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abtiww2RHkA2"
      },
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')  # don't have GPU\n",
        "    return device\n",
        "\n",
        "# convert a df to tensor to be used in pytorch\n",
        "\n",
        "\n",
        "def numpy_to_tensor(ay, tp):\n",
        "    device = get_device()\n",
        "    return torch.from_numpy(ay).type(tp).to(device)\n",
        "\n",
        "\n",
        "class CustomRunner(Runner):\n",
        "\n",
        "    def _handle_batch(self, batch):\n",
        "        x, y = batch\n",
        "        # y_hat, attention = self.model(x)\n",
        "        outputs = self.model(x)\n",
        "\n",
        "        loss = F.cross_entropy(outputs['logits'], y)\n",
        "        accuracy01, accuracy02 = metrics.accuracy(\n",
        "            outputs['logits'], y, topk=(1, 2))\n",
        "        self.batch_metrics = {\n",
        "            \"loss\": loss,\n",
        "            \"accuracy01\": accuracy01,\n",
        "            \"accuracy02\": accuracy02,\n",
        "        }\n",
        "\n",
        "        if self.is_train_loader:\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCIcNtlqKBQy"
      },
      "source": [
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "    def forward(self, x, target, smoothing=0.1):\n",
        "        confidence = 1. - smoothing\n",
        "        logprobs = F.log_softmax(x, dim=-1)\n",
        "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -logprobs.mean(dim=-1)\n",
        "        loss = confidence * nll_loss + smoothing * smooth_loss\n",
        "        return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlcWfNXvI6Q7"
      },
      "source": [
        "\n",
        "#### self attention with lstm\n",
        "\n",
        "\n",
        "class AttentionModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, recurrent_layers, dropout_p):\n",
        "        super(AttentionModel, self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.recurrent_layers = recurrent_layers\n",
        "        self.dropout_p = dropout_p\n",
        "\n",
        "        self.input_embeded = nn.Linear(input_dim, hidden_dim//2)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.lstm = nn.LSTM(input_size=hidden_dim//2, hidden_size=hidden_dim, num_layers=recurrent_layers,\n",
        "                            bidirectional=True)\n",
        "\n",
        "        self.self_attention = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim*2),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(hidden_dim*2, 1)\n",
        "        )\n",
        "\n",
        "        self.scale = 1.0/np.sqrt(hidden_dim)\n",
        "\n",
        "        # initialize LSTM forget gate bias to be 1 as recommanded by http://proceedings.mlr.press/v37/jozefowicz15.pdf\n",
        "        for names in self.lstm._all_weights:\n",
        "            for name in filter(lambda n: \"bias\" in n, names):\n",
        "                bias = getattr(self.lstm, name)\n",
        "                n = bias.size(0)\n",
        "                start, end = n // 4, n // 2\n",
        "                bias.data[start:end].fill_(1.)\n",
        "\n",
        "        self.output_linear = nn.Linear(self.hidden_dim * 2, self.hidden_dim)\n",
        "        self.label = nn.Linear(hidden_dim*4, output_dim)\n",
        "\n",
        "    def forward(self, input_sentences):\n",
        "\n",
        "        input = self.dropout(torch.tanh(self.input_embeded(input_sentences)))\n",
        "        input = input.permute(1, 0, 2)\n",
        "\n",
        "        output, (final_hidden_state, final_cell_state) = self.lstm(\n",
        "            input)\n",
        "        output = output.permute(1, 0, 2)\n",
        "\n",
        "        attn_ene = self.self_attention(output)\n",
        "\n",
        "        attn_ene = attn_ene.view(\n",
        "            input.shape[1], -1)\n",
        "        \n",
        "        # scale\n",
        "        attn_ene.mul_(self.scale)\n",
        "\n",
        "        # # mannual masking, force model focus on previous time index\n",
        "        # mask_one = torch.ones(\n",
        "        #     size=(self.batch_size, attn_ene.shape[1]), dtype=torch.long).to(device)\n",
        "        # mask_zero = torch.zeros(size=(self.batch_size, 30),\n",
        "        #                         dtype=torch.long).to(device)\n",
        "        # mask_one[:, -30:] = mask_zero\n",
        "        # attn_ene = attn_ene.masked_fill(mask_one == 0, -np.inf)\n",
        "\n",
        "        attns = F.softmax(attn_ene, dim=1).unsqueeze(2)\n",
        "\n",
        "        final_inputs = (output * attns).sum(dim=1)\n",
        "        final_inputs2 = output.sum(dim=1)\n",
        "\n",
        "        combined_inputs = torch.cat([final_inputs, final_inputs2], dim=1)\n",
        "\n",
        "        logits = self.label(combined_inputs)\n",
        "\n",
        "        return logits\n",
        "        # return {\"logits\": logits, \"attention\": attention_scores}\n",
        "\n",
        "\n",
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzOSPSpxIMzV",
        "outputId": "b377f204-c68c-4617-d85c-dd29e63b3d90"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATA_DIR = '/content/drive/My Drive/DLDATA/Crop/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xYWOBXh1Ho6H",
        "outputId": "8b8aa8c7-f6a6-4f6c-8e9f-47108c015e4f"
      },
      "source": [
        "# sample data\n",
        "\n",
        "# data_path = '/content/drive/My Drive/DLDATA/Crop/VIC_ready2use150000.csv'\n",
        "# df_all = pd.read_csv(data_path)\n",
        "\n",
        "# # pick up only NDVI,and paddocktyp\n",
        "\n",
        "# df_all = df_all.iloc[:, 6:96].copy()\n",
        "# labels = df_all.columns[1:]\n",
        "\n",
        "# X = df_all[labels]\n",
        "# y = df_all['paddocktyp']\n",
        "\n",
        "\n",
        "##### download data\n",
        "\n",
        "\n",
        "\n",
        "# Filtered data\n",
        "data_path = '/content/drive/My Drive/DLDATA/Crop/VIC_ready2use150000_yz_filtered80210.csv'\n",
        "\n",
        "df_all = pd.read_csv(data_path)\n",
        "labels = df_all.iloc[:,4].copy()\n",
        "columns_name = list(range(0,276))\n",
        "df2 = pd.DataFrame(df_all['VI_values'].str.slice(1,-1).str.split().values.tolist(),columns=columns_name,dtype=float)\n",
        "X = df2.iloc[:,0:183]\n",
        "y = labels\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y)\n",
        "print(le.classes_)\n",
        "class_names = le.classes_\n",
        "y = le.transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=SEED, stratify=y)\n",
        "\n",
        "# # normalizeation\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(X_train)\n",
        "# X_train = scaler.transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# balance data\n",
        "# ros = RandomOverSampler(random_state=SEED)\n",
        "# X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "X_train_resampled, y_train_resampled = X_train, y_train\n",
        "\n",
        "# check sample no.\n",
        "# unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "# print(\"Frequency of unique values of the said array:\")\n",
        "# print(np.asarray((unique_elements, counts_elements)))\n",
        "\n",
        "# unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "# weights = [np.amax(counts_elements)/i for i in counts_elements]\n",
        "# class_weights = torch.FloatTensor(weights).to(device)\n",
        "\n",
        "\n",
        "# DataLoader definition\n",
        "# model hyperparameters\n",
        "INPUT_DIM = 1\n",
        "OUTPUT_DIM = 5\n",
        "HID_DIM = 256\n",
        "DROPOUT = 0.2\n",
        "RECURRENT_Layers = 2\n",
        "EPOCHS = 400\n",
        "BATCH_SIZE = 128\n",
        "num_classes = 5\n",
        "\n",
        "\n",
        "\n",
        "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "weights = [1/i for i in counts_elements]\n",
        "weights[2] = weights[2]/15\n",
        "print(np.asarray((unique_elements, counts_elements)))\n",
        "print(weights)\n",
        "samples_weight = np.array([weights[t] for t in y_train])\n",
        "samples_weights = torch.FloatTensor(samples_weight).to(device)\n",
        "class_weights = torch.FloatTensor(weights).to(device)\n",
        "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weights, len(X_train_resampled),replacement=True)\n",
        "\n",
        "# prepare PyTorch Datasets\n",
        "\n",
        "X_train_tensor = numpy_to_tensor(\n",
        "    X_train_resampled.to_numpy(), torch.FloatTensor)\n",
        "y_train_tensor = numpy_to_tensor(y_train_resampled, torch.long)\n",
        "X_test_tensor = numpy_to_tensor(X_test.to_numpy(), torch.FloatTensor)\n",
        "y_test_tensor = numpy_to_tensor(y_test, torch.long)\n",
        "\n",
        "X_train_tensor = torch.unsqueeze(X_train_tensor, 2)\n",
        "X_test_tensor = torch.unsqueeze(X_test_tensor, 2)\n",
        "\n",
        "train_ds = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "valid_ds = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "\n",
        "# train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
        "#                       shuffle=True, drop_last=True, num_workers=0)\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
        "                      sampler=sampler, drop_last=True, num_workers=0)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE,\n",
        "                      shuffle=False, drop_last=True, num_workers=0)\n",
        "\n",
        "ground_truth = []\n",
        "for i in valid_dl:\n",
        "    ground_truth.append(i[1].cpu().numpy().tolist())\n",
        "\n",
        "# print(ground_truth.flatten())\n",
        "ground_truth = [item for sublist in ground_truth for item in sublist]\n",
        "\n",
        "# Catalyst loader:\n",
        "\n",
        "loaders = OrderedDict()\n",
        "loaders[\"train\"] = train_dl\n",
        "loaders[\"valid\"] = valid_dl\n",
        "\n",
        "# model, criterion, optimizer, scheduler\n",
        "\n",
        "model = AttentionModel(INPUT_DIM, HID_DIM,\n",
        "                        OUTPUT_DIM, RECURRENT_Layers, DROPOUT).to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# criterion = LabelSmoothingCrossEntropy()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.004)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [30,60])\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 10, eta_min=0, last_epoch=-1)\n",
        "\n",
        "# model training\n",
        "# runner = CustomRunner()\n",
        "# logdir = \"./logdir\"\n",
        "# runner.train(\n",
        "#     model=model,\n",
        "#     optimizer=optimizer,\n",
        "#     scheduler=scheduler,\n",
        "#     num_epochs=EPOCHS,\n",
        "#     loaders=loaders,\n",
        "#     logdir=logdir,\n",
        "#     verbose=True,\n",
        "#     timeit=True,\n",
        "#     callbacks=[EarlyStoppingCallback(patience=10)]\n",
        "# )\n",
        "\n",
        "# # model training\n",
        "runner = SupervisedRunner()\n",
        "logdir = \"/content/drive/My Drive/DLDATA/Crop\"\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    verbose=True,\n",
        "    timeit=True,\n",
        "    loaders=loaders,\n",
        "    logdir=logdir,\n",
        "    num_epochs=EPOCHS,\n",
        "    load_best_on_end=True,\n",
        "    main_metric='accuracy01',\n",
        "    minimize_metric=False,\n",
        "    callbacks=[AccuracyCallback(num_classes=5, topk_args=[\n",
        "        1, 2]), EarlyStoppingCallback(metric='accuracy01',minimize=False,patience=10)]\n",
        ")\n",
        "\n",
        "# #### model inference\n",
        "# test_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE,\n",
        "#                      shuffle=False, drop_last=True, num_workers=0)\n",
        "\n",
        "# test_truth = []\n",
        "# for i in test_dl:\n",
        "#     test_truth.append(i[1].cpu().numpy().tolist())\n",
        "\n",
        "# test_truth = [item for sublist in test_truth for item in sublist]\n",
        "\n",
        "# predictions = np.vstack(list(map(\n",
        "#     lambda x: x[\"logits\"].cpu().numpy(),\n",
        "#     runner.predict_loader(model=model,\n",
        "#                           loader=test_dl, resume=f\"{logdir}/checkpoints/best_full.pth\")\n",
        "# )))\n",
        "\n",
        "# probabilities = []\n",
        "# pred_labels = []\n",
        "# true_labels = []\n",
        "# pred_classes = []\n",
        "# true_classes = []\n",
        "# for i, (truth, logits) in enumerate(zip(test_truth, predictions)):\n",
        "#     probability = torch.softmax(torch.from_numpy(logits), dim=0)\n",
        "#     pred_label = probability.argmax().item()\n",
        "#     probabilities.append(probability.cpu().numpy())\n",
        "#     pred_labels.append(pred_label)\n",
        "#     true_labels.append(truth)\n",
        "#     pred_classes.append(class_names[pred_label])\n",
        "#     true_classes.append(class_names[truth])\n",
        "\n",
        "# probabilities_df = pd.DataFrame(probabilities)\n",
        "# true_labels_df = pd.DataFrame(true_labels)\n",
        "# pred_labels_df = pd.DataFrame(pred_labels)\n",
        "# pred_classes_df = pd.DataFrame(pred_classes)\n",
        "# true_classes_df = pd.DataFrame(true_classes)\n",
        "\n",
        "# results = pd.concat([probabilities_df, pred_labels_df, true_labels_df,\n",
        "#                      pred_classes_df, true_classes_df], axis=1)\n",
        "# results.columns = ['Prob_Barley', 'Prob_Canola', 'Prob_Chick_Pea', 'Prob_Lentils',\n",
        "#                    'Prob_Wheat', 'Pred_label', 'True_label', 'Pred_class', 'True_class']\n",
        "\n",
        "# #### classification report\n",
        "\n",
        "# y_true = pred_labels\n",
        "# y_pred = true_labels\n",
        "# target_names = ['Barley', 'Canola', 'Chick Pea', 'Lentils', 'Wheat']\n",
        "# print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n",
        "# #### save predictions as csv\n",
        "# # results.to_csv(f\"{logdir}/predictions/predictions.csv\", index=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Barley' 'Canola' 'Chick Pea' 'Lentils' 'Wheat']\n",
            "[[    0     1     2     3     4]\n",
            " [41161 12097   663 11986 38143]]\n",
            "[2.4294842204999878e-05, 8.266512358435976e-05, 0.00010055304172951233, 8.34306691139663e-05, 2.6217130272920327e-05]\n",
            "\n",
            "\n",
            "\n",
            "1/400 * Epoch (train):   0% 0/812 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d2721960e875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mminimize_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     callbacks=[AccuracyCallback(num_classes=5, topk_args=[\n\u001b[0;32m--> 162\u001b[0;31m         1, 2]), EarlyStoppingCallback(metric='accuracy01',minimize=False,patience=10)]\n\u001b[0m\u001b[1;32m    163\u001b[0m )\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/runners/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, stage_kwargs, checkpoint_data, fp16, distributed, check, overfit, timeit, load_best_on_end, initial_seed, state_kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     def infer(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     ):\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_exception_handler_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     def _batch2device(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/callbacks/exception.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_exception_reraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mcatalyst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExceptionCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    883\u001b[0m             )\n\u001b[1;32m    884\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, stage, epoch)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_loader_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_loader_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_loader\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_batch_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     def _batch2device(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/callbacks/metric.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"IRunner\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;34m\"\"\"Computes metrics and add them to batch metrics.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_computed_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/callbacks/metric.py\u001b[0m in \u001b[0;36m_compute_metric_value\u001b[0;34m(self, output, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/metrics/functional.py\u001b[0m in \u001b[0;36mtopk_metric_with_dict_output\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtopk_metric_with_dict_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/metrics/accuracy.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(outputs, targets, topk, activation)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mcorrect_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
          ]
        }
      ]
    }
  ]
}